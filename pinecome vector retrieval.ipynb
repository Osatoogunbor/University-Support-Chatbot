{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20fb1b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API keys loaded successfully!\n",
      "‚úÖ Pinecone and OpenAI clients initialized!\n",
      "\n",
      "üîµ Welcome to the University Student Support Service!\n",
      "üîπ Speak or type your queries. Say 'exit' or 'quit' to end the conversation.\n",
      "\n",
      "\n",
      "üü¢ Press Enter to speak or type your message: exit\n",
      "üî¥ Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pyaudio\n",
    "import nest_asyncio\n",
    "import openai\n",
    "import speech_recognition as sr\n",
    "from dotenv import load_dotenv\n",
    "from gtts import gTTS\n",
    "from openai import AsyncOpenAI  # Keep this import as you had it\n",
    "from pinecone import Pinecone\n",
    "from transformers import pipeline\n",
    "\n",
    "# ‚úÖ Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# ‚úÖ Access API keys securely\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# ‚úÖ Check if API keys are loaded correctly\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"‚ùå OPENAI_API_KEY not found! Check .env file.\")\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"‚ùå PINECONE_API_KEY not found! Check .env file.\")\n",
    "\n",
    "# ‚úÖ Initialize OpenAI & Pinecone\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# ‚úÖ Define aclient for AsyncOpenAI usage\n",
    "aclient = AsyncOpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(\"ai-powered-chatbot\")\n",
    "\n",
    "print(\"‚úÖ API keys loaded successfully!\")\n",
    "print(\"‚úÖ Pinecone and OpenAI clients initialized!\")\n",
    "\n",
    "# ‚úÖ Load Sentiment Analysis Model\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "def speak_response(text):\n",
    "    try:\n",
    "        audio = pyaudio.PyAudio()\n",
    "        if audio.get_default_input_device_info():\n",
    "            # Proceed with microphone input\n",
    "            recognizer = sr.Recognizer()\n",
    "            with sr.Microphone() as source:\n",
    "                recognizer.adjust_for_ambient_noise(source)\n",
    "                audio_data = recognizer.listen(source)\n",
    "                text = recognizer.recognize_google(audio_data)\n",
    "        else:\n",
    "            print(\"No default input device available. Please check your microphone.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error accessing the microphone: {e}\")\n",
    "\n",
    "# ‚úÖ Generic Intent Responses\n",
    "GENERIC_INTENTS = {\n",
    "    \"hello\": \"Hello! How can I assist you today?\",\n",
    "    \"hi\": \"Hi! How can I help you?\",\n",
    "    \"how are you\": \"I'm just a chatbot, but I'm here to help you! What can I do for you?\",\n",
    "    \"bye\": \"Goodbye! Have a great day!\",\n",
    "    \"exit\": \"Goodbye! Have a great day!\",\n",
    "    \"quit\": \"Goodbye! Have a great day!\",\n",
    "}\n",
    "def detect_generic_intent(query):\n",
    "    query = query.lower().strip()\n",
    "    for intent, response in GENERIC_INTENTS.items():\n",
    "        if intent in query:\n",
    "            return response\n",
    "    return None\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. SENTIMENT ANALYSIS\n",
    "# ------------------------------------------------------------\n",
    "def detect_sentiment(query):\n",
    "    result = sentiment_analyzer(query)[0]\n",
    "    return result['label'].lower()  # e.g. \"positive\", \"negative\", or \"neutral\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. RETRIEVE CHUNKS FROM PINECONE\n",
    "# ------------------------------------------------------------\n",
    "async def retrieve_chunks(query, top_k=2):\n",
    "    try:\n",
    "        response = await aclient.embeddings.create(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            input=[query]\n",
    "        )\n",
    "        query_embedding = response.data[0].embedding\n",
    "\n",
    "        # Query Pinecone\n",
    "        result = index.query(\n",
    "            vector=query_embedding,\n",
    "            top_k=top_k,\n",
    "            include_metadata=True\n",
    "        )\n",
    "\n",
    "        # Extract answers from matches\n",
    "        return [match.metadata.get(\"answer\", \"\") for match in result.matches]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error retrieving chunks: {e}\")\n",
    "        return []\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. SPEECH-TO-TEXT\n",
    "# ------------------------------------------------------------\n",
    "def recognize_speech():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"\\nüé§ Speak now...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "    \n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)  # Uses Google STT\n",
    "        print(f\"üü¢ You said: {text}\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"üî¥ Sorry, I could not understand the speech.\")\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        print(\"üî¥ Could not request results. Check your internet connection.\")\n",
    "        return \"\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. TEXT-TO-SPEECH\n",
    "# ------------------------------------------------------------\n",
    "def speak_response(text):\n",
    "    tts = gTTS(text=text, lang=\"en\")\n",
    "    tts.save(\"response.mp3\")\n",
    "    os.system(\"start response.mp3\")  # Windows-specific approach\n",
    "    \n",
    "    # Alternative offline method using pyttsx3:\n",
    "    # tts_engine.say(text)\n",
    "    # tts_engine.runAndWait()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. GENERATE CHATBOT RESPONSE\n",
    "# ------------------------------------------------------------\n",
    "async def generate_response(query):\n",
    "    # Step 1: Check for generic intents\n",
    "    generic_response = detect_generic_intent(query)\n",
    "    if generic_response:\n",
    "        return generic_response  # No sentiment analysis needed\n",
    "\n",
    "    # Step 2: Detect sentiment (optional usage)\n",
    "    sentiment = detect_sentiment(query)\n",
    "    # (You could do something with 'sentiment' if desired.)\n",
    "\n",
    "    # Step 3: Retrieve relevant chunks\n",
    "    retrieved_chunks = await retrieve_chunks(query)\n",
    "    if not retrieved_chunks:\n",
    "        return \"Unfortunately, I couldn't find relevant information. Please try rephrasing your question.\"\n",
    "\n",
    "    # Step 4: Create GPT prompt\n",
    "    context = \"\\n\".join(retrieved_chunks)\n",
    "    prompt = f\"User's question: {query}\\n\\nRelevant information:\\n{context}\\n\\nAnswer:\"\n",
    "\n",
    "    try:\n",
    "        gpt_response = await aclient.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful and concise assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=200,\n",
    "            temperature=0.6\n",
    "        )\n",
    "\n",
    "        gpt_reply = gpt_response.choices[0].message.content.strip()\n",
    "\n",
    "        # üîπ Check for potential cut-off\n",
    "        if gpt_reply.endswith((\"I'm\", \"but\", \"and\", \"because\", \"These\")):\n",
    "            print(\"üîπ Response may be cut off. Generating continuation...\")\n",
    "            follow_up = await aclient.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Continue the previous response in a concise manner.\"},\n",
    "                    {\"role\": \"user\", \"content\": \"Continue from where you left off.\"}\n",
    "                ],\n",
    "                max_tokens=200,\n",
    "                temperature=0.6\n",
    "            )\n",
    "            gpt_reply += \" \" + follow_up.choices[0].message.content.strip()\n",
    "\n",
    "        return gpt_reply\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating response: {e}\")\n",
    "        return \"Unfortunately, I couldn't generate a response. Please try again.\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. MAIN FUNCTION: VOICE & TEXT SUPPORT\n",
    "# ------------------------------------------------------------\n",
    "async def test_chatbot():\n",
    "    print(\"\\nüîµ Welcome to the University Student Support Service!\")\n",
    "    print(\"üîπ Speak or type your queries. Say 'exit' or 'quit' to end the conversation.\\n\")\n",
    "\n",
    "    while True:\n",
    "        use_voice = input(\"\\nüü¢ Press Enter to speak or type your message: \")\n",
    "        if use_voice == \"\":\n",
    "            query = recognize_speech()\n",
    "            voice_mode = True\n",
    "        else:\n",
    "            query = use_voice\n",
    "            voice_mode = False  # user typed manually\n",
    "        \n",
    "        if query.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"üî¥ Chatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        response = await generate_response(query)\n",
    "        print(f\"\\nüîµ Chatbot: {response}\")\n",
    "\n",
    "        # üîπ Speak the response aloud **ONLY if the user spoke**\n",
    "        if voice_mode:\n",
    "            speak_response(response)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8. ASYNC LOOP SETUP\n",
    "# ------------------------------------------------------------\n",
    "nest_asyncio.apply()  # Fixes async loop issues in some environments\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if sys.platform.startswith(\"win\"):  # Windows fix\n",
    "        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "\n",
    "    try:\n",
    "        asyncio.get_running_loop().run_until_complete(test_chatbot())\n",
    "    except RuntimeError:\n",
    "        asyncio.run(test_chatbot())\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7965c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "You said: hello\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52c25b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
