{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ef96dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API keys loaded successfully!\n",
      "ðŸ“„ Successfully loaded knowledge_base.json.\n",
      "âœ… Embedded entry 1/135\n",
      "âœ… Embedded entry 2/135\n",
      "âœ… Embedded entry 3/135\n",
      "âœ… Embedded entry 4/135\n",
      "âœ… Embedded entry 5/135\n",
      "âœ… Embedded entry 6/135\n",
      "âœ… Embedded entry 7/135\n",
      "âœ… Embedded entry 8/135\n",
      "âœ… Embedded entry 9/135\n",
      "âœ… Embedded entry 10/135\n",
      "âœ… Embedded entry 11/135\n",
      "âœ… Embedded entry 12/135\n",
      "âœ… Embedded entry 13/135\n",
      "âœ… Embedded entry 14/135\n",
      "âœ… Embedded entry 15/135\n",
      "âœ… Embedded entry 16/135\n",
      "âœ… Embedded entry 17/135\n",
      "âœ… Embedded entry 18/135\n",
      "âœ… Embedded entry 19/135\n",
      "âœ… Embedded entry 20/135\n",
      "âœ… Embedded entry 21/135\n",
      "âœ… Embedded entry 22/135\n",
      "âœ… Embedded entry 23/135\n",
      "âœ… Embedded entry 24/135\n",
      "âœ… Embedded entry 25/135\n",
      "âœ… Embedded entry 26/135\n",
      "âœ… Embedded entry 27/135\n",
      "âœ… Embedded entry 28/135\n",
      "âœ… Embedded entry 29/135\n",
      "âœ… Embedded entry 30/135\n",
      "âœ… Embedded entry 31/135\n",
      "âœ… Embedded entry 32/135\n",
      "âœ… Embedded entry 33/135\n",
      "âœ… Embedded entry 34/135\n",
      "âœ… Embedded entry 35/135\n",
      "âœ… Embedded entry 36/135\n",
      "âœ… Embedded entry 37/135\n",
      "âœ… Embedded entry 38/135\n",
      "âœ… Embedded entry 39/135\n",
      "âœ… Embedded entry 40/135\n",
      "âœ… Embedded entry 41/135\n",
      "âœ… Embedded entry 42/135\n",
      "âœ… Embedded entry 43/135\n",
      "âœ… Embedded entry 44/135\n",
      "âœ… Embedded entry 45/135\n",
      "âœ… Embedded entry 46/135\n",
      "âœ… Embedded entry 47/135\n",
      "âœ… Embedded entry 48/135\n",
      "âœ… Embedded entry 49/135\n",
      "âœ… Embedded entry 50/135\n",
      "âœ… Embedded entry 51/135\n",
      "âœ… Embedded entry 52/135\n",
      "âœ… Embedded entry 53/135\n",
      "âœ… Embedded entry 54/135\n",
      "âœ… Embedded entry 55/135\n",
      "âœ… Embedded entry 56/135\n",
      "âœ… Embedded entry 57/135\n",
      "âœ… Embedded entry 58/135\n",
      "âœ… Embedded entry 59/135\n",
      "âœ… Embedded entry 60/135\n",
      "âœ… Embedded entry 61/135\n",
      "âœ… Embedded entry 62/135\n",
      "âœ… Embedded entry 63/135\n",
      "âœ… Embedded entry 64/135\n",
      "âœ… Embedded entry 65/135\n",
      "âœ… Embedded entry 66/135\n",
      "âœ… Embedded entry 67/135\n",
      "âœ… Embedded entry 68/135\n",
      "âœ… Embedded entry 69/135\n",
      "âœ… Embedded entry 70/135\n",
      "âœ… Embedded entry 71/135\n",
      "âœ… Embedded entry 72/135\n",
      "âœ… Embedded entry 73/135\n",
      "âœ… Embedded entry 74/135\n",
      "âœ… Embedded entry 75/135\n",
      "âœ… Embedded entry 76/135\n",
      "âœ… Embedded entry 77/135\n",
      "âœ… Embedded entry 78/135\n",
      "âœ… Embedded entry 79/135\n",
      "âœ… Embedded entry 80/135\n",
      "âœ… Embedded entry 81/135\n",
      "âœ… Embedded entry 82/135\n",
      "âœ… Embedded entry 83/135\n",
      "âœ… Embedded entry 84/135\n",
      "âœ… Embedded entry 85/135\n",
      "âœ… Embedded entry 86/135\n",
      "âœ… Embedded entry 87/135\n",
      "âœ… Embedded entry 88/135\n",
      "âœ… Embedded entry 89/135\n",
      "âœ… Embedded entry 90/135\n",
      "âœ… Embedded entry 91/135\n",
      "âœ… Embedded entry 92/135\n",
      "âœ… Embedded entry 93/135\n",
      "âœ… Embedded entry 94/135\n",
      "âœ… Embedded entry 95/135\n",
      "âœ… Embedded entry 96/135\n",
      "âœ… Embedded entry 97/135\n",
      "âœ… Embedded entry 98/135\n",
      "âœ… Embedded entry 99/135\n",
      "âœ… Embedded entry 100/135\n",
      "âœ… Embedded entry 101/135\n",
      "âœ… Embedded entry 102/135\n",
      "âœ… Embedded entry 103/135\n",
      "âœ… Embedded entry 104/135\n",
      "âœ… Embedded entry 105/135\n",
      "âœ… Embedded entry 106/135\n",
      "âœ… Embedded entry 107/135\n",
      "âœ… Embedded entry 108/135\n",
      "âœ… Embedded entry 109/135\n",
      "âœ… Embedded entry 110/135\n",
      "âœ… Embedded entry 111/135\n",
      "âœ… Embedded entry 112/135\n",
      "âœ… Embedded entry 113/135\n",
      "âœ… Embedded entry 114/135\n",
      "âœ… Embedded entry 115/135\n",
      "âœ… Embedded entry 116/135\n",
      "âœ… Embedded entry 117/135\n",
      "âœ… Embedded entry 118/135\n",
      "âœ… Embedded entry 119/135\n",
      "âœ… Embedded entry 120/135\n",
      "âœ… Embedded entry 121/135\n",
      "âœ… Embedded entry 122/135\n",
      "âœ… Embedded entry 123/135\n",
      "âœ… Embedded entry 124/135\n",
      "âœ… Embedded entry 125/135\n",
      "âœ… Embedded entry 126/135\n",
      "âœ… Embedded entry 127/135\n",
      "âœ… Embedded entry 128/135\n",
      "âœ… Embedded entry 129/135\n",
      "âœ… Embedded entry 130/135\n",
      "âœ… Embedded entry 131/135\n",
      "âœ… Embedded entry 132/135\n",
      "âœ… Embedded entry 133/135\n",
      "âœ… Embedded entry 134/135\n",
      "âœ… Embedded entry 135/135\n",
      "âœ… Embeddings successfully saved to knowledgebase_embeddings.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import asyncio\n",
    "import streamlit as st\n",
    "import speech_recognition as sr\n",
    "import sys\n",
    "import os\n",
    "from openai import AsyncOpenAI  # <-- IMPORTANT: Keep your AsyncOpenAI import\n",
    "from pinecone import Pinecone\n",
    "from transformers import pipeline\n",
    "from gtts import gTTS\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "# âœ… Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# âœ… Access API keys securely\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# âœ… Check if API keys are loaded correctly\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"âŒ OPENAI_API_KEY not found! Check .env file.\")\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"âŒ PINECONE_API_KEY not found! Check .env file.\")\n",
    "\n",
    "# âœ… Initialize OpenAI & Pinecone\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# âœ… Define aclient for AsyncOpenAI usage\n",
    "aclient = AsyncOpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(\"ai-powered-chatbot\")\n",
    "\n",
    "print(\"âœ… API keys loaded successfully!\")\n",
    "print(\"âœ… Pinecone and OpenAI clients initialized!\")\n",
    "\n",
    "\n",
    "# âœ… Load Sentiment Analysis Model\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    revision=\"714eb0f\"\n",
    ")\n",
    "\n",
    "def speak_response(text):\n",
    "    try:\n",
    "        # Generate the speech using gTTS and save it as a temporary file\n",
    "        filename = f\"response_{int(time.time())}.mp3\"\n",
    "        tts = gTTS(text=text, lang=\"en\")\n",
    "        tts.save(filename)\n",
    "\n",
    "        # Cross-platform audio playback\n",
    "        if sys.platform.startswith(\"win\"):\n",
    "            os.system(f'start {filename}')  # Windows\n",
    "        elif sys.platform.startswith(\"linux\"):\n",
    "            os.system(f'xdg-open {filename}')  # Linux\n",
    "        elif sys.platform.startswith(\"darwin\"):\n",
    "            os.system(f'open {filename}')  # macOS\n",
    "        else:\n",
    "            print(\"âŒ Unsupported platform for audio playback.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error playing response: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# âœ… Generic Intent Responses\n",
    "GENERIC_INTENTS = {\n",
    "    \"hello\": \"Hello! How can I assist you today?\",\n",
    "    \"hi\": \"Hi! How can I help you?\",\n",
    "    \"how are you\": \"I'm just a chatbot, but I'm here to help you! What can I do for you?\",\n",
    "    \"bye\": \"Goodbye! Have a great day!\",\n",
    "    \"exit\": \"Goodbye! Have a great day!\",\n",
    "    \"quit\": \"Goodbye! Have a great day!\",\n",
    "}\n",
    "\n",
    "def detect_generic_intent(query):\n",
    "    query = query.lower().strip()\n",
    "    for intent, response in GENERIC_INTENTS.items():\n",
    "        if intent in query:\n",
    "            return response\n",
    "    return None\n",
    "\n",
    "# âœ… Function to Detect Sentiment\n",
    "def detect_sentiment(query):\n",
    "    result = sentiment_analyzer(query)[0]\n",
    "    return result['label'].lower()\n",
    "\n",
    "# âœ… Retrieve Relevant Chunks from Pinecone\n",
    "async def retrieve_chunks(query, top_k=3):\n",
    "    try:\n",
    "        if not query or not isinstance(query, str):\n",
    "            return []\n",
    "\n",
    "        response = await aclient.embeddings.create(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            input=[query.strip()]\n",
    "        )\n",
    "        query_embedding = response.data[0].embedding\n",
    "\n",
    "        result = index.query(\n",
    "            vector=query_embedding,\n",
    "            top_k=top_k,\n",
    "            include_metadata=True\n",
    "        )\n",
    "\n",
    "        return [match.metadata.get(\"answer\", \"\") for match in result.matches]\n",
    "    except Exception as e:\n",
    "        st.error(f\"âŒ Error retrieving chunks: {e}\")\n",
    "        return []\n",
    "\n",
    "# âœ… Function to Convert Speech to Text\n",
    "def recognize_speech():\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        st.info(\"ðŸŽ¤ Speak now...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        st.success(f\"ðŸŸ¢ You said: {text}\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        st.warning(\"ðŸ”´ Sorry, I could not understand the speech.\")\n",
    "        return \"\"\n",
    "    except sr.RequestError:\n",
    "        st.error(\"ðŸ”´ Could not request results. Check your internet connection.\")\n",
    "        return \"\"\n",
    "\n",
    "# âœ… Generate Response\n",
    "async def generate_response(query):\n",
    "    generic_response = detect_generic_intent(query)\n",
    "    if generic_response:\n",
    "        return generic_response\n",
    "\n",
    "    sentiment_task = asyncio.to_thread(detect_sentiment, query)\n",
    "    retrieval_task = retrieve_chunks(query)\n",
    "\n",
    "    sentiment, retrieved_chunks = await asyncio.gather(sentiment_task, retrieval_task)\n",
    "\n",
    "    if not retrieved_chunks:\n",
    "        return \"Unfortunately, I couldn't find relevant information. Please try rephrasing your question.\"\n",
    "\n",
    "    context = \"\\n\".join(retrieved_chunks)\n",
    "    prompt = f\"\"\"\n",
    "    You are a university support chatbot. Answer user queries using the provided relevant information. \n",
    "    Only use the retrieved information and do not add extra knowledge unless necessary.\n",
    "\n",
    "    User Question: {query}\n",
    "\n",
    "    Relevant Information from Knowledge Base:\n",
    "    {context}\n",
    "\n",
    "    Provide a detailed but concise response based on the above information.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response_text = \"\"\n",
    "        # Using GPT-3.5-turbo as an example\n",
    "        gpt_response = await aclient.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\":\n",
    "                    \"You are a university support chatbot. Your responses should be well-structured, informative, and engaging. \"\n",
    "                    \"Expand on key points, avoid generic responses, and ensure clarity. \"\n",
    "                    \"If discussing study techniques, provide examples or step-by-step guidance. \"\n",
    "                    \"Use full sentences rather than short bullet points unless specifically requested.\"\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=300,\n",
    "            temperature=0.5,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        async for chunk in gpt_response:\n",
    "            if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:\n",
    "                response_text += chunk.choices[0].delta.content\n",
    "\n",
    "        return response_text\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error: {e}\"\n",
    "\n",
    "# âœ… Function to display link cards properly\n",
    "def display_link_card(title, description, image_url, link):\n",
    "    st.markdown(\n",
    "        f\"\"\"\n",
    "        <div style=\"border: 1px solid #ddd; border-radius: 12px; padding: 15px; text-align: center; background-color: #f9f9f9; box-shadow: 2px 2px 10px rgba(0,0,0,0.1); width: 100%; max-width: 300px;\">\n",
    "            <a href=\"{link}\" target=\"_blank\" style=\"text-decoration: none;\">\n",
    "                <img src=\"{image_url}\" width=\"100%\" style=\"border-radius: 8px; margin-bottom: 10px;\">\n",
    "                <h4 style=\"margin-bottom: 5px; color: #1A5276; font-size: 16px;\">{title}</h4>\n",
    "                <p style=\"margin: 0px; font-size: 13px; color: #555;\">{description}</p>\n",
    "                <button style=\"background-color: #1E3A8A; color: white; padding: 6px 10px; border: none; border-radius: 6px; cursor: pointer; font-size: 13px; margin-top: 8px;\">\n",
    "                    Visit\n",
    "                </button>\n",
    "            </a>\n",
    "        </div>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "# âœ… Main Streamlit UI\n",
    "def main():\n",
    "    st.markdown(\n",
    "        \"\"\"\n",
    "        <style>\n",
    "            .title {\n",
    "                font-size: 36px;\n",
    "                font-weight: bold;\n",
    "                color: #103c84;\n",
    "                text-align: center;\n",
    "                margin-bottom: 20px;\n",
    "                text-transform: uppercase;\n",
    "            }\n",
    "        </style>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "    st.markdown('<div class=\"title\">ðŸŽ“ University Student Support Chatbot</div>', unsafe_allow_html=True)\n",
    "    st.write(\"ðŸ”¹ Speak or type your queries below. Click **'Start Voice Input'** to speak.\")\n",
    "\n",
    "    # âœ… Chat history container\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state[\"messages\"] = []\n",
    "\n",
    "    with st.container():\n",
    "        for message in st.session_state[\"messages\"]:\n",
    "            with st.chat_message(message[\"role\"]):\n",
    "                st.markdown(message[\"content\"])\n",
    "\n",
    "    st.divider()\n",
    "\n",
    "    # âœ… Chat input\n",
    "    user_input = st.chat_input(\"Type your message here...\")\n",
    "    if user_input:\n",
    "        st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": user_input.strip()})\n",
    "\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        response = loop.run_until_complete(generate_response(user_input.strip()))\n",
    "\n",
    "        st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n",
    "        st.rerun()\n",
    "\n",
    "    st.divider()\n",
    "    if st.button(\"ðŸŽ¤ Start Voice Input\", key=\"voice_button\"):\n",
    "        voice_query = recognize_speech()\n",
    "\n",
    "        if voice_query:\n",
    "            st.session_state[\"messages\"].append({\"role\": \"user\", \"content\": voice_query})\n",
    "\n",
    "            loop = asyncio.new_event_loop()\n",
    "            asyncio.set_event_loop(loop)\n",
    "            response = loop.run_until_complete(generate_response(voice_query))\n",
    "\n",
    "            st.session_state[\"messages\"].append({\"role\": \"assistant\", \"content\": response})\n",
    "            speak_response(response)\n",
    "\n",
    "            st.rerun()\n",
    "\n",
    "    st.divider()\n",
    "    st.subheader(\"ðŸ”— Useful Resources\")\n",
    "\n",
    "    col1, col2, col3 = st.columns(3)\n",
    "\n",
    "    with col1:\n",
    "        display_link_card(\n",
    "            title=\"Mind - Mental Health Support\",\n",
    "            description=\"Get expert advice and resources on managing mental health.\",\n",
    "            image_url=\"https://1000logos.net/wp-content/uploads/2021/12/Mind-Logo.png\",\n",
    "            link=\"https://www.mind.org.uk/\"\n",
    "        )\n",
    "\n",
    "    with col2:\n",
    "        display_link_card(\n",
    "            title=\"Pomodoro Study Technique (YouTube)\",\n",
    "            description=\"Learn how to use the Pomodoro technique for effective studying.\",\n",
    "            image_url=\"https://img.youtube.com/vi/mNBmG24djoY/0.jpg\",\n",
    "            link=\"https://www.youtube.com/watch?v=mNBmG24djoY\"\n",
    "        )\n",
    "\n",
    "    with col3:\n",
    "        display_link_card(\n",
    "            title=\"University of Wolverhampton Support\",\n",
    "            description=\"Explore student support services at your university.\",\n",
    "            image_url=\"https://www.wlv.ac.uk/media/departments/womenx27s-staff-network/Accessibility,-Disability-and-Inclusion-Content-Block-Third.jpg\",\n",
    "            link=\"https://www.wlv.ac.uk/university-life/student-life/\"\n",
    "        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4080b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d587587",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd98b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
